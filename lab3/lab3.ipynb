{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "9a10081f57b90a368eb8daf62e3ba00e",
     "grade": false,
     "grade_id": "cell-02487845739eb4fd",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### Lab 3: Expectation Maximization and Variational Autoencoder\n",
    "\n",
    "### Machine Learning 2 (2017/2018)\n",
    "\n",
    "* The lab exercises should be made in groups of two or three people.\n",
    "* The deadline is Friday, 01.06.\n",
    "* Assignment should be submitted through BlackBoard! Make sure to include your and your teammates' names with the submission.\n",
    "* Attach the .IPYNB (IPython Notebook) file containing your code and answers. Naming of the file should be \"studentid1\\_studentid2\\_lab#\", for example, the attached file should be \"12345\\_12346\\_lab1.ipynb\". Only use underscores (\"\\_\") to connect ids, otherwise the files cannot be parsed.\n",
    "\n",
    "Notes on implementation:\n",
    "\n",
    "* You should write your code and answers in an IPython Notebook: http://ipython.org/notebook.html. If you have problems, please ask.\n",
    "* Use __one cell__ for code and markdown answers only!\n",
    "    * Put all code in the cell with the ```# YOUR CODE HERE``` comment and overwrite the ```raise NotImplementedError()``` line.\n",
    "    * For theoretical questions, put your solution using LaTeX style formatting in the YOUR ANSWER HERE cell.\n",
    "* Among the first lines of your notebook should be \"%pylab inline\". This imports all required modules, and your plots will appear inline.\n",
    "* Large parts of you notebook will be graded automatically. Therefore it is important that your notebook can be run completely without errors and within a reasonable time limit. To test your notebook before submission, select Kernel -> Restart \\& Run All.\n",
    "$\\newcommand{\\bx}{\\mathbf{x}} \\newcommand{\\bpi}{\\mathbf{\\pi}} \\newcommand{\\bmu}{\\mathbf{\\mu}} \\newcommand{\\bX}{\\mathbf{X}} \\newcommand{\\bZ}{\\mathbf{Z}} \\newcommand{\\bz}{\\mathbf{z}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "e4e05229ee79b55d6589e1ea8de68f32",
     "grade": false,
     "grade_id": "cell-a0a6fdb7ca694bee",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### Installing PyTorch\n",
    "\n",
    "In this lab we will use PyTorch. PyTorch is an open source deep learning framework primarily developed by Facebook's artificial-intelligence research group. In order to install PyTorch in your conda environment go to https://pytorch.org and select your operating system, conda, Python 3.6, no cuda. Copy the text from the \"Run this command:\" box. Now open a terminal and activate your 'ml2labs' conda environment. Paste the text and run. After the installation is done you should restart Jupyter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "d9c3d77f550b5fd93b34fd18825c47f0",
     "grade": false,
     "grade_id": "cell-746cac8d9a21943b",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### MNIST data\n",
    "\n",
    "In this Lab we will use several methods for unsupervised learning on the MNIST dataset of written digits. The dataset contains digital images of handwritten numbers $0$ through $9$. Each image has 28x28 pixels that each take 256 values in a range from white ($= 0$) to  black ($=1$). The labels belonging to the images are also included. \n",
    "Fortunately, PyTorch comes with a MNIST data loader. The first time you run the box below it will download the MNIST data set. That can take a couple of minutes.\n",
    "The main data types in PyTorch are tensors. For Part 1, we will convert those tensors to numpy arrays. In Part 2, we will use the torch module to directly work with PyTorch tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "4fbc152afa1255331d7b88bf00b7156c",
     "grade": false,
     "grade_id": "cell-7c995be0fda080c0",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "train_dataset = datasets.MNIST('../data', train=True, download=True,\n",
    "                   transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ]))\n",
    "\n",
    "train_labels = train_dataset.train_labels.numpy()\n",
    "train_data = train_dataset.train_data.numpy()\n",
    "# For EM we will use flattened data\n",
    "train_data = train_data.reshape(train_data.shape[0], -1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "4fc852f9bfb0bab10d4c23eada309e89",
     "grade": false,
     "grade_id": "cell-8b4a44df532b1867",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Part 1: Expectation Maximization\n",
    "We will use the Expectation Maximization (EM) algorithm for the recognition of handwritten digits in the MNIST dataset. The images are modelled as a Bernoulli mixture model (see Bishop $\\S9.3.3$):\n",
    "$$\n",
    "p(\\bx|\\bmu, \\bpi) = \\sum_{k=1}^K  \\pi_k \\prod_{i=1}^D \\mu_{ki}^{x_i}(1-\\mu_{ki})^{(1-x_i)}\n",
    "$$\n",
    "where $x_i$ is the value of pixel $i$ in an image, $\\mu_{ki}$ represents the probability that pixel $i$ in class $k$ is black, and $\\{\\pi_1, \\ldots, \\pi_K\\}$ are the mixing coefficients of classes in the data. We want to use this data set to classify new images of handwritten numbers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "54064637b7e7cf938c0f778d748a226a",
     "grade": false,
     "grade_id": "cell-af03fef663aa85b2",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### 1.1 Binary data (5 points)\n",
    "As we like to apply our Bernoulli mixture model, write a function `binarize` to convert the (flattened) MNIST data to binary images, where each pixel $x_i \\in \\{0,1\\}$, by thresholding at an appropriate level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "fe8607a4d734f7f26ef1ee1e54b33471",
     "grade": false,
     "grade_id": "cell-ec4365531ca57ef3",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def binarize(X):\n",
    "    thresh = X.max() / 2\n",
    "    bin_X = X.copy()\n",
    "    bin_X[bin_X < thresh] = 0\n",
    "    bin_X[bin_X >= thresh] = 1\n",
    "    bin_X = bin_X.astype(np.float)\n",
    "    return bin_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "231b2c9f29bc5c536c60cef4d74793a1",
     "grade": true,
     "grade_id": "cell-2f16f57cb68a83b3",
     "locked": true,
     "points": 5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Test test test!\n",
    "bin_train_data = binarize(train_data)\n",
    "assert bin_train_data.dtype == np.float\n",
    "assert bin_train_data.shape == train_data.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "a0a39404cc2f67078b399ee34653a3ac",
     "grade": false,
     "grade_id": "cell-462e747685e8670f",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Sample a few images of digits $2$, $3$ and $4$; and show both the original and the binarized image together with their label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "3f3c981f0fda5ba3bdfcefb9144305c7",
     "grade": true,
     "grade_id": "cell-784c6bd177a9aa42",
     "locked": false,
     "points": 5,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original digit 2 with index 9727:\n",
      " [[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0 141 253 255 253 170   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0 253 251 253 251 225 168   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  29 197 255 253 254 253 254 253 198  85\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  85 251 253 251 253 251 253 251 253 251\n",
      "  114   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  86 253 255 253 254 196 198 253 254 253\n",
      "  254 139   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  85 251 253 251 253  83  85 251 253 251\n",
      "  253 251   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  57 225 255 253 169   0   0   0 198 253\n",
      "  254 253 169   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0  56  84  83  56   0   0   0  85 251\n",
      "  253 251 168   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 169\n",
      "  254 253 254  84   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  56\n",
      "  253 251 253 196   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "  198 253 254 253  57   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   85 251 253 251 168   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0  29  85 141 253 254 253 254 139  57   0   0   0\n",
      "   85 253 254 253 169   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0  85 251 253 251 253 251 253 251 225 168 114   0\n",
      "   85 251 253 251 168   0   0   0   0   0]\n",
      " [  0   0   0   0   0  57 254 253 226 168 169 168 169 168 254 253 254 253\n",
      "  254 253 254 253 169   0   0   0   0   0]\n",
      " [  0   0   0   0   0  56 253 251 168   0   0   0   0   0  84  83 253 251\n",
      "  253 251 253 251  56   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0 198 253 254 139  85  28   0   0  29  85 141 253\n",
      "  254 253 226  56   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0  85 251 253 251 253 196 169 168 197 251 253 251\n",
      "  253 251 168   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0 114 169 168 254 253 254 253 254 253 254 253\n",
      "  254 253 169   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0  84  83  84  83 253 251 196  83\n",
      "  139 251 168   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]]\n",
      "Binarized digit 2 with index 9727:\n",
      " [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 0. 0. 0. 1. 1. 1. 1. 1. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 1. 1. 1. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 1. 1. 1. 1. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 1. 1. 1. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]] \n",
      "\n",
      "Original digit 2 with index 30355:\n",
      " [[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   4 111 238 202 249 250 122  11\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   6  91 253 253 253 253 254 253 238\n",
      "   49   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0  79 253 253 253 253 236 237 253 253\n",
      "  189  45   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  56 230 253 253 188  84  44  45 158 253\n",
      "  253 152   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0 169 253 253 163  45   0   0   0   7 184\n",
      "  253 207  15   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0 169 253 253  48   0   0   0   0   0  55\n",
      "  229 253 152   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0 129 233 133   9   0   0   0   0   0   0\n",
      "  169 253 240  39   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   7  27   0   0   0   0   0   0   0   0\n",
      "  169 253 253  48   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "  169 253 187   5   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "  169 253 180   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   2\n",
      "  174 254 216  23   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0  18  60  88 145 145  88  25  22 107\n",
      "  253 253 169   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0 106 226 253 253 253 253 253 254 244 217\n",
      "  253 245  51   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   7 186 253 253 253 253 253 253 254 253 253\n",
      "  253 193   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0  37 253 253 253 204  89 182 222 254 253 253\n",
      "  253 193   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0 129 253 253 106  12   0   0 156 254 253 253\n",
      "  253 239  81   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0 118 253 253 125  16   0  37 246 254 253 241\n",
      "  225 253 240  39   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0  23 221 253 253 225 160 233 253 250 145  31\n",
      "  124 253 253 127  14   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0 169 253 253 253 253 253 149  81   0   0\n",
      "    5 136 253 253  94   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   8  40 167 253 253 201   6   0   0   0\n",
      "    0  32 132  92   2   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]]\n",
      "Binarized digit 2 with index 30355:\n",
      " [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 0. 0. 0. 1. 1. 1. 1. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 1. 1. 1. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]] \n",
      "\n",
      "Original digit 2 with index 8743:\n",
      " [[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  87 218 250\n",
      "  128   7   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0  46 169 246 254 254\n",
      "  254  30   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0 117 234 242 148 128 254\n",
      "  254  30   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0  82 220 253 239  71   0   9 221\n",
      "  254  30   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0  82 247 254 197  19   0   0   0 215\n",
      "  254  30   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  70 247 254 199  17   0   0   0   0 215\n",
      "  254  30   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0 154 254 199  19   0   0   0   0  21 228\n",
      "  254  30   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0 100  85   7   0   0   0   0   0  61 254\n",
      "  243  25   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  98 254\n",
      "  184   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  23 216 246\n",
      "   37   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 108 254 196\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  12 217 240  30\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   8  49 116 116 182 254 149   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0  79 213 254 254 254 254 254 123   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  78 245 254 254 254 254 254 254 248 134\n",
      "   26   3   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0 118 245 254 254 254 254 254 207 239 254 254\n",
      "  254 189 110 120  49   3   0   0   0   0]\n",
      " [  0   0   0   0   0   0   2 177 254 254 254 254 219  82   8  57 143 219\n",
      "  243 254 254 255 247 102   0   0   0   0]\n",
      " [  0   0   0   0   0   0  46 254 254 254 254 254  40   0   0   0   0   0\n",
      "   44  65 104  65  65  28   0   0   0   0]\n",
      " [  0   0   0   0   0   0 207 254 254 254 220  37   1   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0 171 254 247 125  27   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]]\n",
      "Binarized digit 2 with index 8743:\n",
      " [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]] \n",
      "\n",
      "Original digit 2 with index 26883:\n",
      " [[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0  49 138 243 191 118\n",
      "   17   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0  17  47 162 161 228 252 252 253 252\n",
      "  227  29   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0 124 252 253 252 252 252 136 131 227\n",
      "  252  77   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0 207 252 253 252 252 252  22   0 161\n",
      "  252 160   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0 103 252 253 252 252 252  22   0 161\n",
      "  252 244  21   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0 106 116 116  84   0   0   3 170\n",
      "  253 203  11   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  45 252\n",
      "  252  87   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 138 252\n",
      "  233  33   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 233 252\n",
      "  183   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 253 252\n",
      "  130   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   9  24  87 138 170 253 148 255 228\n",
      "   32   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0 114 252 253 252 252 252 252 253 132\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  83 240 252 247 183 234 252 252 253 123\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0 184 252 210  42   0 184 252 252 253 223\n",
      "   25   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0  95 246 168  12   0 147 246 252 252 253 252\n",
      "  205  21   0   0   0 168 146   0   0   0]\n",
      " [  0   0   0   0   0   0  24 253 253 161   0 149 253 253 245  21 128 253\n",
      "  253  65  76  87 159 253 150   0   0   0]\n",
      " [  0   0   0   0   0   0  24 252 252 177  99 253 252 240  79   0   9 194\n",
      "  252 252 252 253 252 187  17   0   0   0]\n",
      " [  0   0   0   0   0   0  17 227 252 252 252 253 252 151   0   0   0  65\n",
      "  234 252 221 247 162  19   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0  67 252 252 252 253 172  13   0   0   0   0\n",
      "   33  98  25  42   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0  26 221 210  32 128   8   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]]\n",
      "Binarized digit 2 with index 26883:\n",
      " [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 1.\n",
      "  1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 1. 1. 1. 1. 0. 1. 1. 1. 0. 0. 0. 1. 1.\n",
      "  1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 1. 1. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 1. 1. 1. 1. 1. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]] \n",
      "\n",
      "Original digit 3 with index 19377:\n",
      " [[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0  36  61 148 148 218 253\n",
      "  254 253 191  14   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0  87 190 242 253 252 252 252 252\n",
      "  253 252 252  84   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   9 233 232 251 252 252 253 252 242 231 187\n",
      "  191 252 252 180   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0 132 253 252 252 252 226 190 110  42   0   0\n",
      "   43 252 252 189   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0 167 253 252 155  77  24   0   0   0   0   0\n",
      "   43 252 252 189   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  18\n",
      "  166 253 253  84   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  22 199\n",
      "  253 252 245  56   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   9 128 127 135 237 252\n",
      "  253 252  82   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   6 134 204 253 252 252 252 252\n",
      "  253 196   7   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0 153 252 252 253 252 252 252 252\n",
      "  253 239  62   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0 233 253 253 255 253 250 211 167\n",
      "  237 253 236  14   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0 232 252 252 239 132  58   0   0\n",
      "   69 252 252  84   0   0   0   0   0   0]\n",
      " [  0   0   0  22  48   2   0   0   0   0  19  91  38  17   0   0   0   0\n",
      "   43 252 252 180   0   0   0   0   0   0]\n",
      " [  0   0   0 114 252 167  48   0   0   0   0   0   0   0   0   0   0   0\n",
      "   14 211 252 231  28   0   0   0   0   0]\n",
      " [  0   0   0 148 252 252 242 167  45   0   0   0   0   0   0   0   0   0\n",
      "    0 190 252 252  42   0   0   0   0   0]\n",
      " [  0   0   0  18 141 232 253 253 237 113  39   0   0   0   0   0   0   0\n",
      "   25 227 253 190   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0  32 154 252 253 252 247 190 190 173  85  78  57 128\n",
      "  201 252 252 189   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   6  65 236 252 252 252 252 253 252 251 246 252\n",
      "  253 252 251  86   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  14  84 180 231 252 253 252 252 252 252\n",
      "  253 231  86   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0  28  86 165 252 252 252 164\n",
      "  129  28   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]]\n",
      "Binarized digit 3 with index 19377:\n",
      " [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1. 1. 1. 1. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 1. 1. 1. 1. 1. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]] \n",
      "\n",
      "Original digit 3 with index 6844:\n",
      " [[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0  79 216 212  72   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   7 157 245 254 254 172   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0 129 254 223  91 239 202   5   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0 213 249  94   0 212 254  14   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0 124 254 103   0  26 232 247  13   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0 188 180  11   0  54 254 172   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   7   4   0  19 204 250  64   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   5  66 163 254 237  20   2   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0 126 254 254 254 254 254 164  83  27   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  89 206 173 111 154 206 234 254 216  92\n",
      "   29   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  27 126 209 253\n",
      "  231  84   2   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 128\n",
      "  239 254 119   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   19 191 252 158   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0  15 156 254  76   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0  39 254 187   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0 105 254 172   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   5  75  42   0   0   0   0   0   0\n",
      "    6 165 249 249  21   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  16 227 199  38   0   0   0   0  47 121\n",
      "  202 254 204  55   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  51 237 245 226 226 226 226 226 246 255\n",
      "  240 129  14   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0  30  95 158 158 189 163 158  93  62\n",
      "   37   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]]\n",
      "Binarized digit 3 with index 6844:\n",
      " [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]] \n",
      "\n",
      "Original digit 3 with index 20939:\n",
      " [[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0 128 227 148  18   0  36   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0 127 252 252 217 190 242 163\n",
      "   14  36   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0 127 252 252 253 252 252 252\n",
      "  236 180  92   2   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0  42 111 189 253 252 252 252\n",
      "  252 253 252  91   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  42  77 200 252\n",
      "  252 253 252 223  35   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   4  43  43  43  43 148 253\n",
      "  253 255 253 241  35   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0  22 252 252 253 252 252 252\n",
      "  252 253 252 117   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0  22 252 252 253 252 252 252\n",
      "  235 127  47   2   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0  16 231 252 253 252 252 183\n",
      "   14   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0  81 252 253 252 252 198\n",
      "   18   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  36 224 253\n",
      "  122   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0  43  85  50   0   0   0   0   0   0   0  85 224\n",
      "  252   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0  87 242 252 244 233 118   2   0   0   0   0   0  72\n",
      "  252  62   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0 190 252 252 252 253 252 123  48   0   0   0   0  64\n",
      "  252 239  42   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0 190 252 252 252 253 252 252 215  18   0   0   0 152\n",
      "  252 236  37   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0 191 253 216 106 212 243 253 253 209   0  32 192 253\n",
      "  253 212   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0 155 252 210  50   0  48 158 252 252 191 237 252 252\n",
      "  252  97   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0  43 233 252 244 233 197 234 252 252 253 252 252 221\n",
      "  126   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0 101 252 252 253 252 252 252 252 253 252 252 162\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   4 138 252 253 252 252 252 252 253 173  94  14\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]]\n",
      "Binarized digit 3 with index 20939:\n",
      " [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 1. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]] \n",
      "\n",
      "Original digit 3 with index 11111:\n",
      " [[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0  75 105 245 253 253 255 253 253 182\n",
      "   12   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0  29 104 239 252 252 252 252 253 252 252 252\n",
      "   29   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   4 112 205 252 252 252 246 237 237 253 252 252 252\n",
      "   29   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0 130 252 252 252 252 252  92   0  71 253 252 252 252\n",
      "   29   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0 208 252 252 252 181  29   2  40 240 253 252 194  29\n",
      "    4   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0 191 232 222  90  22   0   0  45 252 253 252  88   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0  28  42   0   0   0   0   0  45 252 253 252 167   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   3 102 253 252 251 167\n",
      "   11   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0 138 252 252 252\n",
      "  200  83   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  43 226 252 252\n",
      "  252 222   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  36 217 253\n",
      "  253 253 253  14   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  29 114\n",
      "  245 252 252 136   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "  214 252 252 220  47   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   40 217 252 252 207   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0 178 252 252 207   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   2  30\n",
      "  162 230 252 252 189   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0 128 134 134 134 134 141 252\n",
      "  252 252 252 204  28   0   0   0   0   0]\n",
      " [  0   0   0   0   0 110 150 167 133 238 238 251 252 252 253 252 252 252\n",
      "  252 252 252 110   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0 171 209 252 252 252 252 252 252 252 253 252 252 252\n",
      "  238 189  59   4   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   7 103 103 103 182 163 137 103 165 252 154 103\n",
      "   73   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]]\n",
      "Binarized digit 3 with index 11111:\n",
      " [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 0. 0. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 0. 0. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]] \n",
      "\n",
      "Original digit 4 with index 45231:\n",
      " [[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  37 253\n",
      "  167  12   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0  44  44   0   0   0   0   0   0   0 132 252\n",
      "  252  21   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0  62 237 237  18   0   0   0   0   0   0 132 252\n",
      "  252  21   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0 132 252 252  21   0   0   0   0   0   0 132 252\n",
      "  252  21   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0 132 252 252  21   0   0   0   0   0   0 132 252\n",
      "  252  21   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0 132 252 252  21   0   0   0   0   0   0 219 252\n",
      "  183   5   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0 132 252 252  74   0   0   0   0   0   0 242 252\n",
      "  164   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0  65 252 252 200  18   0   0   0   0  61 248 252\n",
      "  145   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   6 154 252 252 212 106  10   0   0 100 252 252\n",
      "   88   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0  32 229 252 252 252 224 221 220 233 252 252\n",
      "  241  19   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0 107 220 245 253 255 253 253 253 253\n",
      "  242  19   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0  57  77  77  77 145 252 252\n",
      "  135   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 100 252 252\n",
      "   55   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 100 252 252\n",
      "   64   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 100 252 252\n",
      "   93   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 100 252 252\n",
      "  140   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 100 252 252\n",
      "   64   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 100 252 252\n",
      "   74   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 100 252 252\n",
      "  164   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 100 252 252\n",
      "  164   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]]\n",
      "Binarized digit 4 with index 45231:\n",
      " [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]] \n",
      "\n",
      "Original digit 4 with index 48316:\n",
      " [[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  64 191  64   0   0   0   0   0   0   0\n",
      "    0   0   0   0  64   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0 128 255 255  64   0   0   0   0   0   0   0\n",
      "    0   0 128 255 255   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0  64 255 255 128   0   0   0   0   0   0   0   0\n",
      "    0  64 255 255 128   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0 255 255 191   0   0   0   0   0   0   0   0   0\n",
      "    0 191 255 255   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0 128 255 255 128   0   0   0   0   0   0   0   0   0\n",
      "    0 255 255 191   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0 128 255 255   0   0   0   0   0   0   0   0   0   0\n",
      "   64 255 255 128   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0 255 255 191   0   0   0   0   0   0   0   0   0   0\n",
      "  191 255 255   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0 255 255 191   0   0   0   0   0   0   0   0   0 128\n",
      "  255 255 128   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0 128 255 255  64   0   0   0   0   0   0  64 255 255\n",
      "  255 255  64   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0  64 255 255 255 128  64   0   0 128 191 255 255 255\n",
      "  255 255   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0  64 255 255 255 255 255 255 255 255 255  64 255\n",
      "  255 128   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0 128 191 255 255 255 128  64   0 191 255\n",
      "  255   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 255 255\n",
      "  255   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 255 255\n",
      "  255   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 255 255\n",
      "  255   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 255 255\n",
      "  191   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 255 255\n",
      "  191   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 255 255\n",
      "  255   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 255 255\n",
      "  255   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 191 255\n",
      "  191   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]]\n",
      "Binarized digit 4 with index 48316:\n",
      " [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]] \n",
      "\n",
      "Original digit 4 with index 9147:\n",
      " [[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0 191 255 255   0   0   0\n",
      "    0  64 128   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0 255 255 255   0   0   0\n",
      "    0 128 255 191   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0  64 255 255 191   0   0   0\n",
      "    0 255 255 255   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0 128 255 255  64   0   0   0\n",
      "  128 255 255 191   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0 255 255 128   0   0   0   0\n",
      "  255 255 255  64   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0 128 255 255  64   0   0   0 128\n",
      "  255 255 255   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0 128 255 255  64   0   0   0 191\n",
      "  255 255  64   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0 255 255 128   0   0   0 128 255\n",
      "  255 128   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0 255 255  64   0   0   0 128 255\n",
      "  255   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0 191 255 255   0   0   0  64 255 255\n",
      "   64   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0 255 255 255   0   0   0 255 255 255\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0 255 255 191   0   0  64 255 255 191\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0 255 255   0   0   0 191 255 191   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0 128 255 255   0   0 128 255 255  64   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0 255 255 191   0 255 255 255 191 128\n",
      "  128 255 255 255 191   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0 255 255 255 255 255 255 255 255 255\n",
      "  255 255 255 255 128   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0 191 255 255 255 255 255 255 255\n",
      "  255 128   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0 255 255 255 191 128  64   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0  64 255 255 128   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0 191 255 128   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]]\n",
      "Binarized digit 4 with index 9147:\n",
      " [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 1. 1. 1. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 1. 1. 1. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 1. 1. 1. 1. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 1. 1. 1. 1. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 1. 1. 1. 1. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]] \n",
      "\n",
      "Original digit 4 with index 55821:\n",
      " [[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  47 248\n",
      "  171   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  95 253\n",
      "  215  10   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 157 253\n",
      "  253  35   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 157 253\n",
      "  224  16   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0  38  83   0   0   0   0  14 234 253\n",
      "  200   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0 204 247 116   0   0   0  79 253 253\n",
      "  158   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  24 234 253 139   0   0   0  88 253 253\n",
      "   74   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  53 253 253 133   0   0   7 202 253 206\n",
      "    7   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0 117 253 253  59   9   9 124 254 253 128\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0  52 179 253 253 253 253 253 253 254 253  44\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0  80 221 254 254 254 254 254 254 254 254 255 254 202\n",
      "  118  79  79  79  25  82 227   0   0   0]\n",
      " [  0   0   0   0   0 251 253 253 253 216 111  96  96 155 253 254 253 253\n",
      "  253 253 253 253 247 253 228   0   0   0]\n",
      " [  0   0   0   0   0 232 253 195 126   9   0   0   5 195 253 207 105 126\n",
      "  191 191 191 191 191 158  69   0   0   0]\n",
      " [  0   0   0   0   0  17  26   2   0   0   0   0  97 253 253 157   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0 106 253 253  73   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0 147 253 210   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0  12 219 253 165   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0  33 253 253 165   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0 114 253 253 162   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0  45 129 109  25   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]]\n",
      "Binarized digit 4 with index 55821:\n",
      " [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0.\n",
      "  1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      "  1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0.]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from random import sample\n",
    "\n",
    "def compare_digits(digit, sample_size, training_labels, original_train_data, binarized_train_data):\n",
    "    digit_indices = np.where(training_labels == digit)[0]\n",
    "    sampled_indices = sample(list(digit_indices), k=sample_size)\n",
    "    sampled_original_digits = original_train_data[sampled_indices]\n",
    "    sampled_binarized_digits = binarized_train_data[sampled_indices]\n",
    "    \n",
    "    for sample_index, original_digit, binarized_digit in zip(sampled_indices, sampled_original_digits, sampled_binarized_digits):\n",
    "        print(\"Original digit {} with index {}:\\n\".format(digit, sample_index), original_digit.reshape(28, 28))\n",
    "        print(\"Binarized digit {} with index {}:\\n\".format(digit, sample_index), binarized_digit.reshape(28, 28), \"\\n\")\n",
    "        \n",
    "compare_digits(\n",
    "    digit=2, sample_size=4, training_labels=train_labels, \n",
    "    original_train_data=train_data, binarized_train_data=bin_train_data\n",
    ")\n",
    "\n",
    "compare_digits(\n",
    "    digit=3, sample_size=4, training_labels=train_labels, \n",
    "    original_train_data=train_data, binarized_train_data=bin_train_data\n",
    ")\n",
    "\n",
    "compare_digits(\n",
    "    digit=4, sample_size=4, training_labels=train_labels, \n",
    "    original_train_data=train_data, binarized_train_data=bin_train_data\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "4b9da574d24193df76e96ed8ca62c7b0",
     "grade": false,
     "grade_id": "cell-56b33654497d4052",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### 1.2 Implementation (40 points)\n",
    "You are going to write a function ```EM(X, K, max_iter)``` that implements the EM algorithm on the Bernoulli mixture model. \n",
    "\n",
    "The only parameters the function has are:\n",
    "* ```X``` :: (NxD) array of input training images\n",
    "* ```K``` :: size of the latent space\n",
    "* ```max_iter``` :: maximum number of iterations, i.e. one E-step and one M-step\n",
    "\n",
    "You are free to specify your return statement.\n",
    "\n",
    "Make sure you use a sensible way of terminating the iteration process early to prevent unnecessarily running through all epochs. Vectorize computations using ```numpy``` as  much as possible.\n",
    "\n",
    "You should implement the `E_step(X, mu, pi)` and `M_step(X, gamma)` separately in the functions defined below. These you can then use in your function `EM(X, K, max_iter)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "316c9131692747c363b5db8e9091d362",
     "grade": false,
     "grade_id": "cell-882b13c117a73cc4",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def E_step(X, mu, pi):\n",
    "    print(\"Performing E-Step...\")\n",
    "    # Reponsibility of a data point by a cluster\n",
    "    gamma = np.zeros((X.shape[0], mu.shape[0]))\n",
    "    K = gamma.shape[1]\n",
    "        \n",
    "    # Calculate the probability of a pixel per data point per cluster\n",
    "    pixel_probs = np.array([(mu[k, :] ** X) * ((1-mu[k, :]) ** (1-X)) for k in range(K)])\n",
    "    \n",
    "    assert not numpy.isnan(pixel_probs).any(), \"NaN in pixel_probs\"\n",
    "    \n",
    "    # Calculate the total probability of each data point given each cluster\n",
    "    # by multiplying all the individual pixel probabilities\n",
    "    digit_bernoulli_prob = np.prod(pixel_probs, axis=2)\n",
    "    \n",
    "    assert not numpy.isnan(digit_bernoulli_prob).any(), \"NaN in digit prob\"\n",
    "    \n",
    "    # Calculate the unnormalized gamma values by multiplying the digit probabilites per cluster\n",
    "    # with the cluster probabilities pi_k\n",
    "    unnormalized_gammas = digit_bernoulli_prob.T * pi\n",
    "    norm = np.sum(unnormalized_gammas.T)\n",
    "    assert not numpy.isnan(unnormalized_gammas).any(), \"NaN in unnormalized gammas\"\n",
    "    \n",
    "    # Normalized to obtain gammas\n",
    "    gamma = unnormalized_gammas / norm\n",
    "    gamma[np.isnan(gamma)] = 0\n",
    "    assert not numpy.isnan(gamma).any(), \"NaN in gammas\"\n",
    "    \n",
    "    return gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "1418f4014e98024fc97446ce27766c1d",
     "grade": true,
     "grade_id": "cell-f7c7dd52d82e2498",
     "locked": true,
     "points": 15,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing E-Step...\n"
     ]
    }
   ],
   "source": [
    "# Let's test on 5 datapoints\n",
    "n_test = 5\n",
    "X_test = bin_train_data[:n_test]\n",
    "D_test, K_test = X_test.shape[1], 10\n",
    "\n",
    "np.random.seed(2018)\n",
    "mu_test = np.random.uniform(low=.25, high=.75, size=(K_test,D_test))\n",
    "pi_test = np.ones(K_test) / K_test\n",
    "\n",
    "gamma_test = E_step(X_test, mu_test, pi_test)\n",
    "assert gamma_test.shape == (n_test, K_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "2c426a613653174795cd9c8327ab6e20",
     "grade": false,
     "grade_id": "cell-f1b11b8765bd1ef6",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def M_step(X, gamma):\n",
    "    print(\"Performing M-step...\")\n",
    "    # Get number of clusters\n",
    "    K = gamma.shape[1]\n",
    "    #print(\"K\", K)\n",
    "    #print(\"gamma\", gamma.shape)\n",
    "    \n",
    "    # Get number of points per cluster by summing over all the points\n",
    "    Nk = np.sum(gamma, axis=0)\n",
    "    assert not numpy.isnan(Nk).any(), \"NaN in Nk\"\n",
    "    \n",
    "    # Get the (unnormalized) sum of data points times their gammas for all clusters\n",
    "    mu_sums = np.sum([X.T * gamma[:,k] for k in range(K)], axis=2)\n",
    "    assert not numpy.isnan(mu_sums).any(), \"NaN in mu_sums\"\n",
    "    #print(\"mu sums\", mu_sums.shape)\n",
    "    #print(\"Nk\", Nk.shape)\n",
    "    \n",
    "    # Normalize mus\n",
    "    mu = mu_sums.T / Nk\n",
    "    mu = mu.T\n",
    "    mu[np.isnan(mu)] = 0\n",
    "    assert not numpy.isnan(mu).any(), \"NaN in mu\"\n",
    "    #print(\"mu\", mu.shape)\n",
    "    \n",
    "    # Get cluster probabilities\n",
    "    pi = Nk / sum(Nk)\n",
    "    assert not numpy.isnan(pi).any(), \"NaN in pi\"\n",
    "    \n",
    "    return mu, pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "0f60d48b8b22063cef560b42944a0aa4",
     "grade": true,
     "grade_id": "cell-6e7c751b30acfd45",
     "locked": true,
     "points": 15,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing M-step...\n"
     ]
    }
   ],
   "source": [
    "# Oh, let's test again\n",
    "mu_test, pi_test = M_step(X_test, gamma_test)\n",
    "\n",
    "assert mu_test.shape == (K_test,D_test)\n",
    "assert pi_test.shape == (K_test, )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "acfec6384b058cb0ce1932006fbfebc4",
     "grade": true,
     "grade_id": "cell-d6c4368246dee7e6",
     "locked": false,
     "points": 10,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting iteration #1...\n",
      "Performing E-Step...\n",
      "Performing M-step...\n",
      "Iteration #1 took 0.0 minute(s) and 38.62 second(s).\n",
      "\n",
      "[0.05718319 0.02129674 0.92152007]\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "def EM(X, K, max_iter, mu=None, pi=None):\n",
    "    # Initialize everything\n",
    "    mu = np.random.uniform(low=0.25, high=0.75, size=(K, X.shape[1]))  # Probability of cluster generation this pixel\n",
    "    mu = numpy.divide(mu.T, np.sum(mu, axis=1))  # Normalize\n",
    "    mu = mu.T\n",
    "    pi = np.ones(K) / K # Mixture components\n",
    "    \n",
    "    for iteration in range(max_iter):\n",
    "        print(\"Starting iteration #{}...\".format(iteration+1))\n",
    "        start = time.time()\n",
    "        \n",
    "        gamma = E_step(X, mu, pi)\n",
    "        mu, pi = M_step(X, gamma)\n",
    "        \n",
    "        end = time.time()\n",
    "        duration = end - start\n",
    "        m, s = divmod(duration, 60)\n",
    "        print(\n",
    "            \"Iteration #{} took {} minute(s) and {:.2f} second(s).\\n\".format(iteration+1, m, s)\n",
    "        )\n",
    "        \n",
    "    return gamma, mu, pi\n",
    "\n",
    "EM(bin_train_data, 10, max_iter=1)\n",
    "print(pi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "b4fc12faa0da660f7a4d9cc7deb41b25",
     "grade": false,
     "grade_id": "cell-e1077ed3b83489be",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### 1.3 Three digits experiment (10 points)\n",
    "In analogue with Bishop $\\S9.3.3$, sample a training set consisting of only __binary__ images of written digits $2$, $3$, and $4$. Run your EM algorithm and show the reconstructed digits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "bdbce0fad0ed151063d4c489ce999e3e",
     "grade": true,
     "grade_id": "cell-477155d0264d7259",
     "locked": false,
     "points": 5,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(600, 784)\n",
      "Starting iteration #1...\n",
      "Performing E-Step...\n",
      "Performing M-step...\n",
      "Iteration #1 took 0.0 minute(s) and 0.06 second(s).\n",
      "\n",
      "Starting iteration #2...\n",
      "Performing E-Step...\n",
      "Performing M-step...\n",
      "Iteration #2 took 0.0 minute(s) and 0.03 second(s).\n",
      "\n",
      "Starting iteration #3...\n",
      "Performing E-Step...\n",
      "Performing M-step...\n",
      "Iteration #3 took 0.0 minute(s) and 0.03 second(s).\n",
      "\n",
      "Starting iteration #4...\n",
      "Performing E-Step...\n",
      "Performing M-step...\n",
      "Iteration #4 took 0.0 minute(s) and 0.03 second(s).\n",
      "\n",
      "Starting iteration #5...\n",
      "Performing E-Step...\n",
      "Performing M-step...\n",
      "Iteration #5 took 0.0 minute(s) and 0.03 second(s).\n",
      "\n",
      "Starting iteration #6...\n",
      "Performing E-Step...\n",
      "Performing M-step...\n",
      "Iteration #6 took 0.0 minute(s) and 0.03 second(s).\n",
      "\n",
      "Starting iteration #7...\n",
      "Performing E-Step...\n",
      "Performing M-step...\n",
      "Iteration #7 took 0.0 minute(s) and 0.04 second(s).\n",
      "\n",
      "Starting iteration #8...\n",
      "Performing E-Step...\n",
      "Performing M-step...\n",
      "Iteration #8 took 0.0 minute(s) and 0.03 second(s).\n",
      "\n",
      "Starting iteration #9...\n",
      "Performing E-Step...\n",
      "Performing M-step...\n",
      "Iteration #9 took 0.0 minute(s) and 0.03 second(s).\n",
      "\n",
      "Starting iteration #10...\n",
      "Performing E-Step...\n",
      "Performing M-step...\n",
      "Iteration #10 took 0.0 minute(s) and 0.03 second(s).\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def create_digits_train_data(train_data, train_labels, digits, size):\n",
    "    digits_train_data = []\n",
    "    \n",
    "    for digit in digits:\n",
    "        digit_indices = np.where(train_labels == digit)[0]\n",
    "        sampled_indices = sample(list(digit_indices), k=int(size/len(digits)))\n",
    "        digit_samples = train_data[sampled_indices]\n",
    "        digits_train_data.append(digit_samples)\n",
    "    \n",
    "    return np.concatenate(digits_train_data)\n",
    "\n",
    "three_digits = [2, 3, 4]\n",
    "three_digits_train = create_digits_train_data(bin_train_data, train_labels, three_digits, size=600)\n",
    "print(three_digits_train.shape)\n",
    "\n",
    "gamma, mu, pi = EM(three_digits_train, 3, max_iter=10)\n",
    "\n",
    "for mu_index in range(mu.shape[0]):\n",
    "    plt.figure()\n",
    "    plt.title(\"Latent space #{}\".format(mu_index+1))\n",
    "    current_mu = mu[mu_index, :].reshape(28, 28)\n",
    "    plt.imshow(current_mu, cmap='hot', interpolation='nearest')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "485543f4893938d2a9dc1c17d8221cbc",
     "grade": false,
     "grade_id": "cell-88c9664f995b1909",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Can you identify which element in the latent space corresponds to which digit? What are the identified mixing coefficients for digits $2$, $3$ and $4$, and how do these compare to the true ones?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "ae7b5acea6089e2590059f90b0d0a0be",
     "grade": true,
     "grade_id": "cell-3680ae2159c48193",
     "locked": false,
     "points": 5,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "98e04feb59a36867367b3027df9e226d",
     "grade": false,
     "grade_id": "cell-0891dda1c3e80e9a",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### 1.4 Experiments (20 points)\n",
    "Perform the follow-up experiments listed below using your implementation of the EM algorithm. For each of these, describe/comment on the obtained results and give an explanation. You may still use your dataset with only digits 2, 3 and 4 as otherwise computations can take very long."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "439067186fa3ef1d7261a9bcf5a84ea6",
     "grade": false,
     "grade_id": "cell-06fe1b1355689928",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "#### 1.4.1 Size of the latent space (5 points)\n",
    "Run EM with $K$ larger or smaller than the true number of classes. Describe your results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "791512aeadd30c4b586b966ca10e6fad",
     "grade": true,
     "grade_id": "cell-6c9057f2546b7215",
     "locked": false,
     "points": 2,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "e12e40c2d2165e3bb500b5504128910d",
     "grade": true,
     "grade_id": "cell-f01c37653160244b",
     "locked": false,
     "points": 3,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "b306681523a2e35eea310ac10bb68999",
     "grade": false,
     "grade_id": "cell-cf478d67239b7f2e",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "#### 1.4.2 Identify misclassifications (10 points)\n",
    "How can you use the data labels to assign a label to each of the clusters/latent variables? Use this to identify images that are 'misclassified' and try to understand why they are. Report your findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "000c11bd8756a4e24296c7c55d3ee17e",
     "grade": true,
     "grade_id": "cell-daa1a492fbba5c7e",
     "locked": false,
     "points": 5,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "baf43434481c13d76ad51e3ba07e2bf5",
     "grade": true,
     "grade_id": "cell-329245c02df7850d",
     "locked": false,
     "points": 5,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "640bc57a2d08c3becf534bb5e4b35971",
     "grade": false,
     "grade_id": "cell-67ce1222e8a7837b",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "#### 1.4.3 Initialize with true values (5 points)\n",
    "Initialize the three classes with the true values of the parameters and see what happens. Report your results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "a48f788e286458ef0f776865a3bcd58b",
     "grade": true,
     "grade_id": "cell-aa5d6b9f941d985d",
     "locked": false,
     "points": 2,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "1dc4adf3081f3bec93f94c3b12b87db9",
     "grade": true,
     "grade_id": "cell-981e44f35a3764b0",
     "locked": false,
     "points": 3,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "bd613f41e5d2b7d22b0d5b1e7644a48a",
     "grade": false,
     "grade_id": "cell-19bfd7cf4017ed84",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Part 2: Variational Auto-Encoder\n",
    "\n",
    "A Variational Auto-Encoder (VAE) is a probabilistic model $p(\\bx, \\bz)$ over observed variables $\\bx$ and latent variables and/or parameters $\\bz$. Here we distinguish the decoder part, $p(\\bx | \\bz) p(\\bz)$ and an encoder part $p(\\bz | \\bx)$ that are both specified with a neural network. A lower bound on the log marginal likelihood $\\log p(\\bx)$ can be obtained by approximately inferring the latent variables z from the observed data x using an encoder distribution $q(\\bz| \\bx)$ that is also specified as a neural network. This lower bound is then optimized to fit the model to the data. \n",
    "\n",
    "The model was introduced by Diederik Kingma (during his PhD at the UVA) and Max Welling in 2013, https://arxiv.org/abs/1312.6114. \n",
    "\n",
    "Since it is such an important model there are plenty of well written tutorials that should help you with the assignment. E.g: https://jaan.io/what-is-variational-autoencoder-vae-tutorial/.\n",
    "\n",
    "In the following, we will make heavily use of the torch module, https://pytorch.org/docs/stable/index.html. Most of the time replacing `np.` with `torch.` will do the trick, e.g. `np.sum` becomes `torch.sum` and `np.log` becomes `torch.log`. In addition, we will use `torch.FloatTensor()` as an equivalent to `np.array()`. In order to train our VAE efficiently we will make use of batching. The number of data points in a batch will become the first dimension of our data tensor, e.g. A batch of 128 MNIST images has the dimensions [128, 1, 28, 28]. To check check the dimensions of a tensor you can call `.size()`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "92bd337f41c3f94777f47376c7149ca7",
     "grade": false,
     "grade_id": "cell-bcbe35b20c1007d3",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### 2.1 Loss function\n",
    "The objective function (variational lower bound), that we will use to train the VAE, consists of two terms: a log Bernoulli loss (reconstruction loss) and a KullbackLeibler divergence. We implement the two terms separately and combine them in the end.\n",
    "As seen in Part 1: Expectation Maximization, we can use a multivariate Bernoulli distribution to model the likelihood $p(\\bx | \\bz)$ of black and white images. Formally, the variational lower bound is maximized but in PyTorch we are always minimizing therefore we need to calculate the negative log Bernoulli loss and KullbackLeibler divergence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "3fb5f70b132e1233983ef89d19998374",
     "grade": false,
     "grade_id": "cell-389d81024af846e5",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### 2.1.1 Negative Log Bernoulli loss (5 points)\n",
    "The negative log Bernoulli loss is defined as,\n",
    "\n",
    "\\begin{align}\n",
    "loss = - (\\sum_i^D \\bx_i \\log \\hat{\\bx_i} + (1  \\bx_i) \\log(1  \\hat{\\bx_i})).\n",
    "\\end{align}\n",
    "\n",
    "Write a function `log_bernoulli_loss` that takes a D dimensional vector `x`, its reconstruction `x_hat` and returns the negative log Bernoulli loss. Make sure that your function works for batches of arbitrary size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "952435ca03f47ab67a7e88b8306fc9a0",
     "grade": false,
     "grade_id": "cell-1d504606d6f99145",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def log_bernoulli_loss(x_hat, x):\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "bd2a490aa694507bd032e86d77fc0087",
     "grade": true,
     "grade_id": "cell-9666dad0b2a9f483",
     "locked": true,
     "points": 5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "### Test test test\n",
    "x_test = torch.FloatTensor([[0.1, 0.2, 0.3, 0.4], [0.5, 0.6, 0.7, 0.8], [0.9, 0.9, 0.9, 0.9]])\n",
    "x_hat_test = torch.FloatTensor([[0.11, 0.22, 0.33, 0.44], [0.55, 0.66, 0.77, 0.88], [0.99, 0.99, 0.99, 0.99]])\n",
    "\n",
    "assert log_bernoulli_loss(x_hat_test, x_test) > 0.0\n",
    "assert log_bernoulli_loss(x_hat_test, x_test) < 10.0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "6b75b7a531ecc87bce57925c4da464ee",
     "grade": false,
     "grade_id": "cell-b3a7c02dee7aa505",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### 2.1.2 Negative KullbackLeibler divergence (10 Points)\n",
    "The variational lower bound (the objective to be maximized) contains a KL term $D_{KL}(q(\\bz)||p(\\bz))$ that can often be calculated analytically. In the VAE we assume $q = N(\\bz, \\mu, \\sigma^2I)$ and $p = N(\\bz, 0, I)$. Solve analytically!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "d01a7e7fe2dcf5f1c5fb955b85c8a04a",
     "grade": true,
     "grade_id": "cell-4cab10fd1a636858",
     "locked": false,
     "points": 5,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "328115c94a66e8aba0a62896e647c3ba",
     "grade": false,
     "grade_id": "cell-c49899cbf2a49362",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Write a function `KL_loss` that takes two J dimensional vectors `mu` and `logvar` and returns the negative KullbackLeibler divergence. Where `logvar` is $\\log(\\sigma^2)$. Make sure that your function works for batches of arbitrary size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "33b14b79372dd0235d67bb66921cd3e0",
     "grade": false,
     "grade_id": "cell-125b41878005206b",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def KL_loss(mu, logvar):\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "cf72e196d2b60827e8e940681ac50a07",
     "grade": true,
     "grade_id": "cell-ba714bbe270a3f39",
     "locked": true,
     "points": 5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "### Test test test\n",
    "mu_test = torch.FloatTensor([[0.1, 0.2], [0.3, 0.4], [0.5, 0.6]])\n",
    "logvar_test = torch.FloatTensor([[0.01, 0.02], [0.03, 0.04], [0.05, 0.06]])\n",
    "\n",
    "assert KL_loss(mu_test, logvar_test) > 0.0\n",
    "assert KL_loss(mu_test, logvar_test) < 10.0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "65335a588baac26bc48dd6c4d275fdca",
     "grade": false,
     "grade_id": "cell-18cb3f8031edec23",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### 2.1.3 Putting the losses together (5 points)\n",
    "Write a function `loss_function` that takes a D dimensional vector `x`, its reconstruction `x_hat`, two J dimensional vectors `mu` and `logvar` and returns the final loss. Make sure that your function works for batches of arbitrary size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "f6ecb5b60b2c8d7b90070ed59320ee70",
     "grade": false,
     "grade_id": "cell-d2d18781683f1302",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def loss_function(x_hat, x, mu, logvar):\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "816e9508408bfcb2c7332b508d505081",
     "grade": true,
     "grade_id": "cell-57747988d29bbb5d",
     "locked": true,
     "points": 5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "x_test = torch.FloatTensor([[0.1, 0.2, 0.3], [0.4, 0.5, 0.6], [0.7, 0.8, 0.9]])\n",
    "x_hat_test = torch.FloatTensor([[0.11, 0.22, 0.33], [0.44, 0.55, 0.66], [0.77, 0.88, 0.99]])\n",
    "mu_test = torch.FloatTensor([[0.1, 0.2], [0.3, 0.4], [0.5, 0.6]])\n",
    "logvar_test = torch.FloatTensor([[0.01, 0.02], [0.03, 0.04], [0.05, 0.06]])\n",
    "\n",
    "assert loss_function(x_hat_test, x_test, mu_test, logvar_test) > 0.0\n",
    "assert loss_function(x_hat_test, x_test, mu_test, logvar_test) < 10.0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "4506e06ed44a0535140582277a528ba4",
     "grade": false,
     "grade_id": "cell-9e3ba708967fe918",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### 2.2 The model\n",
    "Below you see a data structure for the VAE. The modell itself consists of two main parts the encoder (images $\\bx$ to latent variables $\\bz$) and the decoder (latent variables $\\bz$ to images $\\bx$). The encoder is using 3 fully-connected layers, whereas the decoder is using fully-connected layers. Right now the data structure is quite empty, step by step will update its functionality. For test purposes we will initialize a VAE for you. After the data structure is completed you will do the hyperparameter search.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "31eccf2f6600764e28eb4bc6c5634e49",
     "grade": false,
     "grade_id": "cell-e7d9dafee18f28a1",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from torch.nn import functional as F \n",
    "\n",
    "class VAE(nn.Module):\n",
    "    def __init__(self, fc1_dims, fc21_dims, fc22_dims, fc3_dims, fc4_dims):\n",
    "        super(VAE, self).__init__()\n",
    "\n",
    "        self.fc1 = nn.Linear(*fc1_dims)\n",
    "        self.fc21 = nn.Linear(*fc21_dims)\n",
    "        self.fc22 = nn.Linear(*fc22_dims)\n",
    "        self.fc3 = nn.Linear(*fc3_dims)\n",
    "        self.fc4 = nn.Linear(*fc4_dims)\n",
    "\n",
    "    def encode(self, x):\n",
    "        # To be implemented\n",
    "        raise Exception('Method not implemented')\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        # To be implemented\n",
    "        raise Exception('Method not implemented')\n",
    "\n",
    "    def decode(self, z):\n",
    "        # To be implemented\n",
    "        raise Exception('Method not implemented')\n",
    "\n",
    "    def forward(self, x):\n",
    "        # To be implemented\n",
    "        raise Exception('Method not implemented')\n",
    "\n",
    "VAE_test = VAE(fc1_dims=(784, 4), fc21_dims=(4, 2), fc22_dims=(4, 2), fc3_dims=(2, 4), fc4_dims=(4, 784))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "1a2243397998b4f55c25dfd734f3e7e0",
     "grade": false,
     "grade_id": "cell-c4f9e841b8972a43",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### 2.3 Encoding (10 points)\n",
    "Write a function `encode` that gets a vector `x` with 784 elements (flattened MNIST image) and returns `mu` and `logvar`. Your function should use three fully-connected layers (`self.fc1()`, `self.fc21()`, `self.fc22()`). First, you should use `self.fc1()` to embed `x`. Second, you should use `self.fc21()` and `self.fc22()` on the embedding of `x` to compute `mu` and `logvar` respectively. PyTorch comes with a variety of activation functions, the most common calls are `F.relu()`, `F.sigmoid()`, `F.tanh()`. Make sure that your function works for batches of arbitrary size.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "628bcd88c611cf01e70f77854600199b",
     "grade": false,
     "grade_id": "cell-93cb75b98ae76569",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def encode(self, x):\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    return mu, logvar\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "370d930fa9f10f1d3a451f3805c04d88",
     "grade": true,
     "grade_id": "cell-9648960b73337a70",
     "locked": true,
     "points": 10,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "### Test, test, test\n",
    "VAE.encode = encode\n",
    "\n",
    "x_test = torch.ones((5,784))\n",
    "mu_test, logvar_test = VAE_test.encode(x_test)\n",
    "\n",
    "assert np.allclose(mu_test.size(), [5, 2])\n",
    "assert np.allclose(logvar_test.size(), [5, 2])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "6f597cc2b5ef941af282d7162297f865",
     "grade": false,
     "grade_id": "cell-581b4ed1996be868",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### 2.4 Reparameterization (10 points)\n",
    "One of the major question that the VAE is answering, is 'how to take derivatives with respect to the parameters of a stochastic variable?', i.e. if we are given $\\bz$ that is drawn from a distribution $q(\\bz|\\bx)$, and we want to take derivatives. This step is necessary to be able to use gradient-based optimization algorithms like SGD.\n",
    "For some distributions, it is possible to reparameterize samples in a clever way, such that the stochasticity is independent of the parameters. We want our samples to deterministically depend on the parameters of the distribution. For example, in a normally-distributed variable with mean $\\mu$ and standard deviation $\\sigma$, we can sample from it like this:\n",
    "\n",
    "\\begin{align}\n",
    "\\bz = \\mu + \\sigma \\odot \\epsilon,\n",
    "\\end{align}\n",
    "\n",
    "where $\\odot$ is the element-wise multiplication and $\\epsilon$ is sampled from $N(0, I)$.\n",
    "\n",
    "\n",
    "Write a function `reparameterize` that takes two J dimensional vectors `mu` and `logvar`. It should return $\\bz = \\mu + \\sigma \\odot \\epsilon$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "6331cb5dd23aaacbcf1a52cfecb1afaa",
     "grade": false,
     "grade_id": "cell-679aea8b2adf7ec4",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def reparameterize(self, mu, logvar):\n",
    "            \n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "        return z\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "38d4e047717ab334b262c8c177f0a420",
     "grade": true,
     "grade_id": "cell-fdd7b27a3d17f84e",
     "locked": true,
     "points": 10,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "### Test, test, test\n",
    "VAE.reparameterize = reparameterize\n",
    "VAE_test.train()\n",
    "\n",
    "mu_test = torch.FloatTensor([[0.1, 0.2], [0.3, 0.4], [0.5, 0.6]])\n",
    "logvar_test = torch.FloatTensor([[0.01, 0.02], [0.03, 0.04], [0.05, 0.06]])\n",
    "\n",
    "z_test = VAE_test.reparameterize(mu_test, logvar_test)\n",
    "\n",
    "assert np.allclose(z_test.size(), [3, 2])\n",
    "assert z_test[0][0] < 5.0\n",
    "assert z_test[0][0] > -5.0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "9241ab0eaf8366c37ad57072ce66f095",
     "grade": false,
     "grade_id": "cell-0be851f9f7f0a93e",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### 2.5 Decoding (10 points)\n",
    "Write a function `decode` that gets a vector `z` with J elements and returns a vector `x_hat` with 784 elements (flattened MNIST image). Your function should use two fully-connected layers (`self.fc3()`, `self.fc4()`). PyTorch comes with a variety of activation functions, the most common calls are `F.relu()`, `F.sigmoid()`, `F.tanh()`. Make sure that your function works for batches of arbitrary size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "e8e833cfd7c54a9b67a38056d5d6cab8",
     "grade": false,
     "grade_id": "cell-bf92bb3878275a41",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def decode(self, z):\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    return x_hat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "7732293fd7d971fcf255496e8c68638d",
     "grade": true,
     "grade_id": "cell-4abb91cb9e80af5d",
     "locked": true,
     "points": 10,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# test test test\n",
    "VAE.decode = decode\n",
    "\n",
    "z_test = torch.ones((5,2))\n",
    "x_hat_test = VAE_test.decode(z_test)\n",
    "\n",
    "assert np.allclose(x_hat_test.size(), [5, 784])\n",
    "assert (x_hat_test <= 1).all()\n",
    "assert (x_hat_test >= 0).all()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "e2e113d1f45398b2a1399c336526e755",
     "grade": false,
     "grade_id": "cell-97511fbc4f5b469b",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### 2.6 Forward pass (10)\n",
    "To complete the data structure you have to define a forward pass through the VAE. A single forward pass consists of the encoding of an MNIST image $\\bx$ into latent space $\\bz$, the reparameterization of $\\bz$ and the decoding of $\\bz$ into an image $\\bx$.\n",
    "\n",
    "Write a function `forward` that gets a a vector `x` with 784 elements (flattened MNIST image) and returns a vector `x_hat` with 784 elements (flattened MNIST image), `mu` and `logvar`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "8b7433c4631dd01c07a5fe287e55ae13",
     "grade": false,
     "grade_id": "cell-26bb463b9f98ebd5",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def forward(self, x):\n",
    "    x = x.view(-1, 784)\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    return x_hat, mu, logvar\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "8e7e495f40465c162512e9873c360b25",
     "grade": true,
     "grade_id": "cell-347e5fba3d02754b",
     "locked": true,
     "points": 10,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# test test test \n",
    "VAE.forward = forward\n",
    "\n",
    "x_test = torch.ones((5,784))\n",
    "x_hat_test, mu_test, logvar_test = VAE_test.forward(x_test)\n",
    "\n",
    "assert np.allclose(x_hat_test.size(), [5, 784])\n",
    "assert np.allclose(mu_test.size(), [5, 2])\n",
    "assert np.allclose(logvar_test.size(), [5, 2])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "a114a6fd781fb949b887e6a028e07946",
     "grade": false,
     "grade_id": "cell-62c89e4d3b253671",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### 2.7 Training (15)\n",
    "We will now train the VAE using an optimizer called Adam, https://arxiv.org/abs/1412.6980. The code to train a model in PyTorch is given below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "f3b6bb965fb48229c63cacda48baea65",
     "grade": false,
     "grade_id": "cell-be75f61b09f3b9b6",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "\n",
    "def train(epoch, train_loader, model, optimizer):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for batch_idx, (data, _) in enumerate(train_loader):\n",
    "        data = Variable(data)\n",
    "        optimizer.zero_grad()\n",
    "        recon_batch, mu, logvar = model(data)\n",
    "        loss = loss_function(recon_batch, data.view(-1, 784), mu, logvar)\n",
    "        loss.backward()\n",
    "        train_loss += loss.data\n",
    "        optimizer.step()\n",
    "        if batch_idx % 100 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader),\n",
    "                loss.data / len(data)))\n",
    "\n",
    "    print('====> Epoch: {} Average loss: {:.4f}'.format(\n",
    "          epoch, train_loss / len(train_loader.dataset)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "48ca730dbef06a668f4dfdb24888f265",
     "grade": false,
     "grade_id": "cell-da1b063b7de850b9",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Let's train. You have to choose the hyperparameters. Make sure your loss is going down in a reasonable amount of epochs (around 10)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "846430258fb80f50b161135448726520",
     "grade": false,
     "grade_id": "cell-d4d4408d397f6967",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "# fc1_dims = (?,?)\n",
    "# fc21_dims =\n",
    "# fc22_dims =\n",
    "# fc3_dims =\n",
    "# fc4_dims =\n",
    "# lr =\n",
    "# batch_size =\n",
    "# epochs =\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "b93390f399b743276bc25e67493344f2",
     "grade": true,
     "grade_id": "cell-ca352d8389c1809a",
     "locked": true,
     "points": 15,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# This cell contains a hidden test, please don't delete it, thx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "20719070ed85964de9722acc3456a515",
     "grade": false,
     "grade_id": "cell-5c77370db7cec9f2",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Run the box below to train the model using the hyperparameters you entered above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "38306be3638e85812bd5b2a052fcc0a4",
     "grade": false,
     "grade_id": "cell-5712d42de1068398",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "from torch import nn, optim\n",
    "\n",
    "# Load data\n",
    "train_data = datasets.MNIST('../data', train=True, download=True,\n",
    "                   transform=transforms.ToTensor())\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data,\n",
    "                                           batch_size=batch_size, shuffle=True, **{})\n",
    "\n",
    "# Init model\n",
    "VAE_MNIST = VAE(fc1_dims=fc1_dims, fc21_dims=fc21_dims, fc22_dims=fc22_dims, fc3_dims=fc3_dims, fc4_dims=fc4_dims)\n",
    "\n",
    "# Init optimizer\n",
    "optimizer = optim.Adam(VAE_MNIST.parameters(), lr=lr)\n",
    "\n",
    "# Train\n",
    "for epoch in range(1, epochs + 1):\n",
    "    train(epoch, train_loader, VAE_MNIST, optimizer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "e2f8fcc9384e30cb154cf931f223898b",
     "grade": false,
     "grade_id": "cell-bd07c058c661b9c6",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "Run the box below to check if the model you trained above is able to correctly reconstruct images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "80d198e03b1287741d761a12e38dcf73",
     "grade": false,
     "grade_id": "cell-df03d717307a6863",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "### Let's check if the reconstructions make sense\n",
    "# Set model to test mode\n",
    "VAE_MNIST.eval()\n",
    "    \n",
    "# Reconstructed\n",
    "train_data_plot = datasets.MNIST('../data', train=True, download=True,\n",
    "                   transform=transforms.ToTensor())\n",
    "\n",
    "train_loader_plot = torch.utils.data.DataLoader(train_data_plot,\n",
    "                                           batch_size=1, shuffle=False, **{})\n",
    "\n",
    "for batch_idx, (data, _) in enumerate(train_loader_plot):\n",
    "    x_hat, mu, logvar = VAE_MNIST(data)\n",
    "    plt.imshow(x_hat.view(1,28,28).squeeze().data.numpy(), cmap='gray')\n",
    "    plt.title('%i' % train_data.train_labels[batch_idx])\n",
    "    plt.show()\n",
    "    if batch_idx == 3:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "7f559122b150f5f1228d6b66b62f462c",
     "grade": false,
     "grade_id": "cell-76649d51fdf133dc",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### 2.8 Visualize latent space (20 points)\n",
    "Now, implement the auto-encoder now with a 2-dimensional latent space, and train again over the MNIST data. Make a visualization of the learned manifold by using a linearly spaced coordinate grid as input for the latent space, as seen in  https://arxiv.org/abs/1312.6114 Figure 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "c879ffdb0d355349d7144a33d16ca93a",
     "grade": true,
     "grade_id": "cell-4a0af6d08d055bee",
     "locked": false,
     "points": 20,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "b9eb1684d646eea84a25638d184bfbda",
     "grade": false,
     "grade_id": "cell-dc5e1247a1e21009",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### 2.8 Amortized inference (10 points)\n",
    "What is amortized inference? Where in the code of Part 2 is it used? What is the benefit of using it?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "364ed922da59070f319d0bdfb0e41d92",
     "grade": true,
     "grade_id": "cell-6f7808a9b0098dbf",
     "locked": false,
     "points": 10,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
